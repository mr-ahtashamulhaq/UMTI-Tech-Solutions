---
title: RAG Voice Assistant
emoji: ğŸ™ï¸
colorFrom: blue
colorTo: indigo
sdk: docker
pinned: false
---

# RAG Voice Assistant

A production-ready **Retrieval-Augmented Generation (RAG)** assistant that answers questions about your documents by text **or** voice  with spoken audio responses.<br>

<a href="https://rag-voice-assistant-three.vercel.app" target="_blank">
  <img src="https://img.shields.io/badge/Live-Demo-000000?style=for-the-badge&logo=vercel&logoColor=3B82F6" alt="Live Demo">
</a>

---

## Architecture Overview

```
User (browser)
   â”‚  text question     â”€â”€â–¶  POST /query
   â”‚  voice recording   â”€â”€â–¶  POST /voice/ask
   â”‚  document ingest   â”€â”€â–¶  POST /ingest
   â–¼
FastAPI backend  (src/api/main.py)
   â”œâ”€â”€ Ingestion pipeline
   â”‚     â”œâ”€â”€ Document Loader   â€“ reads PDF / DOCX / TXT   (src/ingestion/document_loader.py)
   â”‚     â”œâ”€â”€ Chunker           â€“ splits text into chunks   (src/ingestion/chunker.py)
   â”‚     â””â”€â”€ Embedder          â€“ Gemini embeddings â†’ ChromaDB  (src/ingestion/embedder.py)
   â”‚
   â”œâ”€â”€ RAG pipeline  (src/rag/pipeline.py)
   â”‚     â”œâ”€â”€ Retriever  â€“ embeds query, queries ChromaDB
   â”‚     â””â”€â”€ Generator  â€“ Groq LLaMA builds grounded answer
   â”‚
   â””â”€â”€ Voice pipeline
         â”œâ”€â”€ ASR  â€“ Groq Whisper transcribes audio  (src/voice/asr.py)
         â””â”€â”€ TTS  â€“ gTTS converts answer to mp3     (src/voice/tts.py)
```

---

## Tech Stack

| Layer | Technology |
|---|---|
| API framework | FastAPI + Uvicorn |
| LLM | Groq â€” `llama-3.3-70b-versatile` |
| Embeddings | Google Gemini â€” `gemini-embedding-001` |
| Vector store | ChromaDB (persistent) |
| ASR | Groq â€” `whisper-large-v3` |
| TTS | gTTS (Google Text-to-Speech) |
| Text splitting | LangChain `RecursiveCharacterTextSplitter` |
| Document parsing | pypdf, python-docx |
| Frontend | Plain HTML + CSS + JavaScript (single file) |

---

## Setup

### Prerequisites
- Python 3.11+
- A [Groq API key](https://console.groq.com/)
- A [Google AI / Gemini API key](https://aistudio.google.com/app/apikey)

### 1 â€” Clone
```bash
git clone https://github.com/your-username/rag-voice-assistant.git
cd rag-voice-assistant
```

### 2 â€” Create virtual environment & install dependencies
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

pip install -r requirements.txt
```

### 3 â€” Add API keys
Create a `.env` file in the project root:
```env
GROQ_API_KEY=your_groq_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
```

### 4 â€” Add your documents
Drop PDF, DOCX, or TXT files into the `data/` folder.

### 5 â€” Run the server
```bash
python run.py
```

The API will be available at **http://localhost:8000**  
Interactive docs at **http://localhost:8000/docs**

---

## Running with Docker

```bash
# Build
docker build -t rag-voice-assistant .

# Run (mount data folder and pass API keys)
docker run -p 8000:8000 \
  -e GROQ_API_KEY=your_groq_key \
  -e GEMINI_API_KEY=your_gemini_key \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/chroma_db:/app/chroma_db \
  rag-voice-assistant
```

---

## How to Use

### Ingest documents
1. Place files in `data/`
2. Open the frontend at `frontend/index.html` and click **Reload Documents**, or call:
```bash
curl -X POST http://localhost:8000/ingest
```

### Ask by text
Type a question in the **Ask by Text** box and press Enter or click **Ask**.

Or via API:
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the main topic of the documents?"}'
```

### Ask by voice
1. Click **Record** and speak your question
2. Click **Stop** â€” the audio is transcribed and sent to the RAG pipeline
3. The answer is displayed as text and played back as audio

Or via API:
```bash
curl -X POST http://localhost:8000/voice/ask \
  -F "file=@question.wav"
```

---

## API Endpoints

| Method | Path | Description |
|---|---|---|
| GET | `/health` | Server health check |
| POST | `/query` | Text question â†’ RAG answer |
| POST | `/ingest` | Ingest all files in `data/` |
| POST | `/voice/transcribe` | Audio file â†’ transcribed text |
| POST | `/voice/ask` | Audio file â†’ RAG answer + TTS mp3 |
| GET | `/voice/audio` | Serve generated TTS audio file |

---

## Folder Structure

```
rag-voice-assistant/
â”œâ”€â”€ data/                        # Drop your documents here
â”œâ”€â”€ chroma_db/                   # Persistent vector store (auto-created)
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html               # Single-file dark-themed UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py              # FastAPI app + all endpoints
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ document_loader.py   # PDF / DOCX / TXT reader
â”‚   â”‚   â”œâ”€â”€ chunker.py           # Text splitter
â”‚   â”‚   â””â”€â”€ embedder.py          # Gemini embeddings â†’ ChromaDB
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ pipeline.py          # Retrieve + generate answer
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ asr.py               # Groq Whisper transcription
â”‚       â””â”€â”€ tts.py               # gTTS text-to-speech
â”œâ”€â”€ run.py                       # Server entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ .env                         # API keys (never commit this)
```

---

## License

MIT License â€” see [LICENSE](LICENSE) for details.
